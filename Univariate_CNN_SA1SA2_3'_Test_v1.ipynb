{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports and functions\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D,Input, Flatten\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "nuc_arr = ['A','C','G','T']\n",
    "#Function for calculating modified probability of splicing at SD1, only considering SD1 and SD2\n",
    "def prob_SD1 (sd1_freq, sd2_freq): \n",
    "    if (sd1_freq==0 and sd2_freq==0):\n",
    "        return 0.0 \n",
    "    else:\n",
    "        return sd1_freq/(sd1_freq+sd2_freq)\n",
    "def prob_site (site_freq, total_freq):\n",
    "    if (total_freq==0):\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(site_freq)/total_freq\n",
    "#Function converting nucleotide sequence to numerical array with 4 channels\n",
    "def seq_to_arr (seq):\n",
    "    seq_len = len(seq)\n",
    "    arr_rep = np.zeros((seq_len, len(nuc_arr))) \n",
    "    for i in range(seq_len):\n",
    "        arr_rep[i][nuc_arr.index(seq[i])] = 1 \n",
    "    return arr_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating a modified dataset with only the necessary information\n",
    "#Storing model inputs and outputs\n",
    "reads_path = 'GSM1911084_A3SS_spliced_reads.txt'\n",
    "seq_path = 'GSM1911083_A3SS_seq.txt'\n",
    "s1_indx = 236\n",
    "s2_indx= 389\n",
    "seq_len = 80\n",
    "read_lines = []\n",
    "seq_lines = []\n",
    "data_table = []\n",
    "\n",
    "#Getting all sequences\n",
    "with open(seq_path) as f:\n",
    "    f.readline() \n",
    "    for line in f:\n",
    "        mod_line = line.split('\\t') \n",
    "        seq_lines.append([mod_line[0], mod_line[1][:-1]])\n",
    "        \n",
    "#Getting all relevant read frequencies\n",
    "with open(reads_path) as f:\n",
    "    f.readline() \n",
    "    for line in f:\n",
    "        mod_line = line.split('\\t')\n",
    "        read_lines.append([mod_line[0], mod_line[s1_indx], mod_line[s2_indx]])\n",
    "        \n",
    "n = len(read_lines)\n",
    "prob_s1 = np.zeros(n)\n",
    "inputs = np.zeros((n,seq_len, 4))\n",
    "\n",
    "with open('3SS_compressed.txt', 'w') as f: \n",
    "    for i in range(n):\n",
    "        data_table.append([read_lines[i][0], seq_lines[i][1], read_lines[i][1], read_lines[i][2]])\n",
    "        f.write(read_lines[i][0]+'\\t'+seq_lines[i][1]+'\\t'+read_lines[i][1]+ '\\t'+read_lines[i][2] + '\\n')\n",
    "        prob_s1[i] = prob_SD1(float(read_lines[i][1]), float(read_lines[i][2]))\n",
    "        inputs[i] = seq_to_arr(seq_lines[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1990565/1990565 [==============================] - 229s 115us/step - loss: 0.0177\n",
      "Epoch 2/2\n",
      "1990565/1990565 [==============================] - 229s 115us/step - loss: 0.0174\n",
      "Model 1 r2 on Testing Data:\n",
      "0.11747698356624015\n"
     ]
    }
   ],
   "source": [
    "#Creating, training, and testing model_1, a somewhat simpler model\n",
    "#Architecture 1: Input -> Conv -> Pool -> Conv -> Pool -> FC -> FC\n",
    "model_1 = models.Sequential([\n",
    "    Conv1D(seq_len//2,(4), strides=1, input_shape=(seq_len,len(nuc_arr)), activation='relu'),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    Conv1D(seq_len//4, (4), strides=1, activation='relu'),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    Flatten(),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "#Compiling and training\n",
    "model_1.compile(optimizer=optimizers.Adam(lr=0.001), loss='mean_squared_error')\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(inputs, prob_s1,test_size=0.1, random_state=40) \n",
    "model_1.fit(x=X_train_1, y=y_train_1, epochs=2) \n",
    "#Testing\n",
    "y_pred_1 = model_1.predict(X_test_1) \n",
    "print(\"Model 1 r2 on Testing Data:\") \n",
    "print(r2_score(y_test_1, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1990565/1990565 [==============================] - 369s 185us/step - loss: 0.0185\n",
      "Epoch 2/2\n",
      "1990565/1990565 [==============================] - 365s 183us/step - loss: 0.0183\n",
      "Model 2 r2 on Testing Data:\n",
      "0.07737825372849572\n"
     ]
    }
   ],
   "source": [
    "#Creating, training, and testing model_2, a slightly deeper network\n",
    "#Architecture 2: Input -> Conv -> Conv -> Pool -> Conv -> Conv -> Pool -> FC -> FC\n",
    "model_2 = models.Sequential([\n",
    "    Conv1D(seq_len,(4), input_shape=(seq_len,len(nuc_arr)), activation='relu'),\n",
    "    Conv1D(seq_len,(4), input_shape=(seq_len,len(nuc_arr)), activation='relu'),\n",
    "    MaxPooling1D(pool_size=5),\n",
    "    Conv1D(seq_len//2,(4), input_shape=(seq_len,len(nuc_arr)), activation='relu'),\n",
    "    Conv1D(seq_len//2,(4), input_shape=(seq_len,len(nuc_arr)), activation='relu'),\n",
    "    MaxPooling1D(pool_size=5),\n",
    "    Flatten(),\n",
    "    Dense(40, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "#Compiling and training\n",
    "model_2.compile(optimizer=optimizers.Adam(lr=0.001), loss='mean_squared_error')\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(inputs, prob_s1,test_size=0.1, random_state=40) \n",
    "model_2.fit(x=X_train_2, y=y_train_2, epochs=2) \n",
    "#Testing\n",
    "y_pred_2 = model_2.predict(X_test_2) \n",
    "print(\"Model 2 r2 on Testing Data:\") \n",
    "print(r2_score(y_test_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#BELOW, MODELS ARE TRAINED TO PREDICT TOTAL READ FRACTION AT SA1, SA2, Crypt, not Binary Fraction\n",
    "#Creating a modified dataset with only the necessary information\n",
    "#Storing model inputs and outputs\n",
    "reads_path = 'GSM1911084_A3SS_spliced_reads.txt'\n",
    "seq_path = 'GSM1911083_A3SS_seq.txt'\n",
    "s1_indx = 236\n",
    "s2_indx= 389\n",
    "crypt_indx = 373\n",
    "seq_len = 80\n",
    "read_lines = []\n",
    "seq_lines = []\n",
    "\n",
    "#Getting all sequences\n",
    "with open(seq_path) as f:\n",
    "    f.readline() \n",
    "    for line in f:\n",
    "        mod_line = line.split('\\t') \n",
    "        seq_lines.append([mod_line[0], mod_line[1][:-1]])\n",
    "        \n",
    "#Getting all relevant read frequencies\n",
    "with open(reads_path) as f:\n",
    "    f.readline() \n",
    "    for line in f:\n",
    "        mod_line = line.split('\\t')\n",
    "        total_reads = sum([int(j) for j in mod_line[1:]])\n",
    "        read_lines.append([mod_line[0], prob_site (mod_line[s1_indx], total_reads), prob_site (mod_line[s2_indx], total_reads), prob_site (mod_line[crypt_indx], total_reads)])\n",
    "\n",
    "n = len(read_lines)\n",
    "prob_s1 = np.zeros(n)\n",
    "prob_s2 = np.zeros(n)\n",
    "prob_cr = np.zeros(n)\n",
    "inputs = np.zeros((n,seq_len, 4))\n",
    "\n",
    "for i in range(n):\n",
    "    prob_s1[i] = float(read_lines[i][1])\n",
    "    prob_s2[i] = float(read_lines[i][2])\n",
    "    prob_cr[i] = float(read_lines[i][3])\n",
    "    inputs[i] = seq_to_arr(seq_lines[i][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1990565/1990565 [==============================] - 228s 114us/step - loss: 0.0169\n",
      "Epoch 2/2\n",
      "1990565/1990565 [==============================] - 228s 115us/step - loss: 0.0166\n",
      "Model 1 r2 on Training Data for SA1:\n",
      "0.12484327987776656\n",
      "Model 1 r2 on Testing Data for SA1:\n",
      "0.1219766311251902\n",
      "Epoch 1/2\n",
      "1990565/1990565 [==============================] - 354s 178us/step - loss: 0.0176\n",
      "Epoch 2/2\n",
      "1990565/1990565 [==============================] - 352s 177us/step - loss: 0.0174\n",
      "Model 2 r2 on Training Data for SA1:\n",
      "0.07072624372190128\n",
      "Model 2 r2 on Testing Data for SA1:\n",
      "0.0670908755481806\n"
     ]
    }
   ],
   "source": [
    "#SA1 Prediction\n",
    "#Creating, training, and testing model_1, a somewhat simpler model\n",
    "#Architecture 1: Input -> Conv -> Pool -> Conv -> Pool -> FC -> FC\n",
    "model_1 = models.Sequential([\n",
    "    Conv1D(seq_len//2,(4), strides=1, input_shape=(seq_len,len(nuc_arr)), activation='relu'),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    Conv1D(seq_len//4, (4), strides=1, activation='relu'),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    Flatten(),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "model_1.compile(optimizer=optimizers.Adam(lr=0.001), loss='mean_squared_error')\n",
    "#Training Model 1\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(inputs, prob_s1,test_size=0.1, random_state=40) \n",
    "model_1.fit(x=X_train_1, y=y_train_1, epochs=2) \n",
    "#Testing\n",
    "y_pred_1_tr = model_1.predict(X_train_1)\n",
    "print(\"Model 1 r2 on Training Data for SA1:\")\n",
    "print(r2_score(y_train_1, y_pred_1_tr))\n",
    "y_pred_1 = model_1.predict(X_test_1) \n",
    "print(\"Model 1 r2 on Testing Data for SA1:\") \n",
    "print(r2_score(y_test_1, y_pred_1))\n",
    "\n",
    "#Creating, training, and testing model_2, a slightly deeper network\n",
    "#Architecture 2: Input -> Conv -> Conv -> Pool -> Conv -> Conv -> Pool -> FC -> FC\n",
    "model_2 = models.Sequential([\n",
    "    Conv1D(seq_len,(4), input_shape=(seq_len,len(nuc_arr)), activation='relu'),\n",
    "    Conv1D(seq_len,(4), input_shape=(seq_len,len(nuc_arr)), activation='relu'),\n",
    "    MaxPooling1D(pool_size=5),\n",
    "    Conv1D(seq_len//2,(4), input_shape=(seq_len,len(nuc_arr)), activation='relu'),\n",
    "    Conv1D(seq_len//2,(4), input_shape=(seq_len,len(nuc_arr)), activation='relu'),\n",
    "    MaxPooling1D(pool_size=5),\n",
    "    Flatten(),\n",
    "    Dense(40, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "model_2.compile(optimizer=optimizers.Adam(lr=0.001), loss='mean_squared_error')\n",
    "#Training Model 2\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(inputs, prob_s1,test_size=0.1, random_state=40) \n",
    "model_2.fit(x=X_train_2, y=y_train_2, epochs=2) \n",
    "#Testing\n",
    "y_pred_2_tr = model_2.predict(X_train_2)\n",
    "print(\"Model 2 r2 on Training Data for SA1:\")\n",
    "print(r2_score(y_train_2, y_pred_2_tr))\n",
    "y_pred_2 = model_2.predict(X_test_2) \n",
    "print(\"Model 2 r2 on Testing Data for SA1:\") \n",
    "print(r2_score(y_test_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1990565/1990565 [==============================] - 231s 116us/step - loss: 0.1754\n",
      "Epoch 2/2\n",
      "1990565/1990565 [==============================] - 234s 118us/step - loss: 0.1746\n",
      "Model 1 r2 on Training Data for SA2:\n",
      "0.0881002651992695\n",
      "Model 1 r2 on Testing Data for SA2:\n",
      "0.08494280263877951\n",
      "Epoch 1/2\n",
      "1990565/1990565 [==============================] - 359s 180us/step - loss: 0.1833\n",
      "Epoch 2/2\n",
      "1990565/1990565 [==============================] - 358s 180us/step - loss: 0.1816\n",
      "Model 2 r2 on Training Data for SA2:\n",
      "0.052681205761415995\n",
      "Model 2 r2 on Testing Data for SA2:\n",
      "0.050646736380798196\n"
     ]
    }
   ],
   "source": [
    "#SA2 Prediction\n",
    "#Creating, training, and testing model_1, a somewhat simpler model\n",
    "#Architecture 1: Input -> Conv -> Pool -> Conv -> Pool -> FC -> FC\n",
    "\n",
    "#Training Model 1\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(inputs, prob_s2,test_size=0.1, random_state=40) \n",
    "model_1.fit(x=X_train_1, y=y_train_1, epochs=2) \n",
    "#Testing Model 1\n",
    "y_pred_1_tr = model_1.predict(X_train_1)\n",
    "print(\"Model 1 r2 on Training Data for SA2:\")\n",
    "print(r2_score(y_train_1, y_pred_1_tr))\n",
    "y_pred_1 = model_1.predict(X_test_1) \n",
    "print(\"Model 1 r2 on Testing Data for SA2:\") \n",
    "print(r2_score(y_test_1, y_pred_1))\n",
    "\n",
    "#Creating, training, and testing model_2, a slightly deeper network\n",
    "#Architecture 2: Input -> Conv -> Conv -> Pool -> Conv -> Conv -> Pool -> FC -> FC\n",
    "#Training Model 2\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(inputs, prob_s2,test_size=0.1, random_state=40) \n",
    "model_2.fit(x=X_train_2, y=y_train_2, epochs=2) \n",
    "#Testing Model 2\n",
    "y_pred_2_tr = model_2.predict(X_train_2)\n",
    "print(\"Model 2 r2 on Training Data for SA2:\")\n",
    "print(r2_score(y_train_2, y_pred_2_tr))\n",
    "y_pred_2 = model_2.predict(X_test_2) \n",
    "print(\"Model 2 r2 on Testing Data for SA2:\") \n",
    "print(r2_score(y_test_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1990565/1990565 [==============================] - 233s 117us/step - loss: 0.0194\n",
      "Epoch 2/2\n",
      "1990565/1990565 [==============================] - 232s 117us/step - loss: 0.0191\n",
      "Model 1 r2 on Training Data for SACrypt:\n",
      "0.0008624130192416146\n",
      "Model 1 r2 on Testing Data for SACrypt:\n",
      "0.00080778351508215\n",
      "Epoch 1/2\n",
      "1990565/1990565 [==============================] - 361s 181us/step - loss: 0.0193\n",
      "Epoch 2/2\n",
      "1990565/1990565 [==============================] - 361s 182us/step - loss: 0.0192\n",
      "Model 2 r2 on Training Data for SACrypt:\n",
      "0.0002886424975629964\n",
      "Model 2 r2 on Testing Data for SACrypt:\n",
      "0.0002489518243189437\n"
     ]
    }
   ],
   "source": [
    "#Crypt Prediction\n",
    "#Creating, training, and testing model_1, a somewhat simpler model\n",
    "#Architecture 1: Input -> Conv -> Pool -> Conv -> Pool -> FC -> FC\n",
    "\n",
    "#Training Model 1\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(inputs, prob_cr,test_size=0.1, random_state=40) \n",
    "model_1.fit(x=X_train_1, y=y_train_1, epochs=2) \n",
    "#Testing Model 1\n",
    "y_pred_1_tr = model_1.predict(X_train_1)\n",
    "print(\"Model 1 r2 on Training Data for SACrypt:\")\n",
    "print(r2_score(y_train_1, y_pred_1_tr))\n",
    "y_pred_1 = model_1.predict(X_test_1) \n",
    "print(\"Model 1 r2 on Testing Data for SACrypt:\") \n",
    "print(r2_score(y_test_1, y_pred_1))\n",
    "\n",
    "#Training Model 2\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(inputs, prob_cr,test_size=0.1, random_state=40) \n",
    "model_2.fit(x=X_train_2, y=y_train_2, epochs=2) \n",
    "#Testing Model 2\n",
    "y_pred_2_tr = model_2.predict(X_train_2)\n",
    "print(\"Model 2 r2 on Training Data for SACrypt:\")\n",
    "print(r2_score(y_train_2, y_pred_2_tr))\n",
    "y_pred_2 = model_2.predict(X_test_2) \n",
    "print(\"Model 2 r2 on Testing Data for SACrypt:\") \n",
    "print(r2_score(y_test_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
