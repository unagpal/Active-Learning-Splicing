{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MaxEntBinaryAcquisition.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"cYMZe2uUUW6I","colab_type":"code","outputId":"2f8e83db-5846-4c80-8ad5-623fb883cde7","executionInfo":{"status":"ok","timestamp":1588348902346,"user_tz":240,"elapsed":1872,"user":{"displayName":"Udai Nagpal","photoUrl":"","userId":"01029084257713971836"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["%tensorflow_version 1.x\n","\n","import numpy as np\n","import keras\n","from keras.datasets import mnist\n","import sys\n","from scipy.stats import entropy\n","import matplotlib.pyplot as plt\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Dropout, Activation, Flatten, SpatialDropout2D\n","from keras.layers.convolutional import Convolution2D, MaxPooling2D\n","from keras.regularizers import l2\n","from keras import backend as K\n","\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zEIatE30Udo9","colab_type":"code","colab":{}},"source":["def predict_with_uncertainty(f, x, n_iter=100):\n","    \"\"\"Function generating non-deterministic predictions using MC dropout and returning the mean of these predictions\n","    Adapted from: https://stackoverflow.com/questions/43529931/how-to-calculate-prediction-uncertainty-using-keras\n","    #Arguments:\n","        f: function mapping model input and Keras backend learning_phase flag to model output\n","        x: input\n","        n_iter: number of repreated MC dropout predictions per point\n","    #Returns:\n","        Mean of MC dropout predictions\n","    \"\"\"\n","    result = np.zeros((n_iter,x.shape[0], 2))\n","    for i in range(n_iter):\n","        predictions = np.array(f((x, 1))[0])\n","        result[i,:, :] = predictions\n","    prediction = result.mean(axis=0)\n","    return prediction\n","\n","#Used for making repeated pool predictions\n","def predict_pool_with_uncertainty(f, x, n_iter=50):\n","    \"\"\"Function generating and returning non-deterministic predictions using MC dropout\n","    Adapted from: https://stackoverflow.com/questions/43529931/how-to-calculate-prediction-uncertainty-using-keras\n","    #Arguments:\n","        f: function mapping model input and Keras backend learning_phase flag to model output\n","        x: input\n","        n_iter: number of repreated MC dropout predictions per point\n","    #Returns:\n","        All MC dropout predictions\n","    \"\"\"\n","    result = np.zeros((n_iter,x.shape[0], 2))\n","    for i in range(n_iter):\n","        predictions = np.array(f((x, 1))[0])\n","        result[i,:, :] = predictions\n","    return result\n","\n","\n","def run_model (train_data_indices, pool_sample_indices):\n","    \"\"\"Initializes and trains a Keras model from scratch on the given training data, returning test MAE and MSE (and MC dropout predictions for D_{sample})\n","    #Arguments\n","        train_data_indices: indices within X_train_All of current training points\n","        pool_sample_indices: indices within X_train_All of pool points in the selected sample D_{sample}\n","    #Returns\n","        Test accuracy and MC dropout predictions for all pool points in D_{sample}\n","    \"\"\"\n","  X_train = np.expand_dims(X_train_All[train_data_indices], axis=1)\n","  y_train = y_train_All[train_data_indices]\n","  y_train[y_train==7] = 1\n","  y_train[y_train==9] = 0\n","  y_train = keras.utils.to_categorical(y_train, num_classes=2)\n","  train_size = y_train.shape[0]\n","  Weight_Decay = 0.0005/train_size\n","  dropout_prob = 0.30\n","  batch_size=128\n","  nb_filters = 35\n","  nb_pool = 3\n","  nb_conv = 4\n","  img_rows = img_cols = 28\n","  nb_classes = 2\n","  model = Sequential()\n","  model.add(Convolution2D(nb_filters, nb_conv, strides=1, data_format=\"channels_first\", input_shape=(1, img_rows, img_cols)))\n","  model.add(Activation('relu'))\n","  model.add(Convolution2D(nb_filters, nb_conv, data_format=\"channels_first\", strides=2))\n","  model.add(Activation('relu'))\n","  model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool), data_format=\"channels_first\"))\n","  model.add(Dropout(dropout_prob))\n","  model.add(Flatten())\n","  model.add(Dense(128, W_regularizer=l2(Weight_Decay)))\n","  model.add(Activation('relu'))\n","  model.add(Dropout(dropout_prob))\n","  model.add(Dense(nb_classes, W_regularizer=l2(Weight_Decay)))\n","  model.add(Activation('softmax'))\n","  model.compile(loss='categorical_crossentropy', optimizer='adam')\n","  model.fit(X_train, y_train, epochs=300, batch_size=128, verbose=0)\n","  f = K.function([model.layers[0].input, K.learning_phase()],[model.layers[-1].output])\n","  y_test_output = predict_with_uncertainty(f, X_test, n_iter=100)\n","  y_test_predictions = np.argmax(y_test_output, axis=1)\n","  pool_sample_predictions = predict_pool_with_uncertainty(f, np.expand_dims(X_train_All[pool_sample_indices], axis=1), n_iter=50)\n","  return [np.sum(y_test_predictions==y_test_original)/(y_test_original.shape[0]), pool_sample_predictions]\n","\n","\n","\n","def get_acquisition_fn(pool_forward_pass):\n","  \"\"\"Evaluates Max Entropy acquisition function (pool_forward_pass shape is [num_masks (J), number of pool candidate points, number of classes])\n","  #Arguments:\n","      pool_forward_pass: MC dropout predictions on candidate points for acquisition in the pool\n","  #Returns:\n","      Value of Max Entropy acquisition function for each pool candidate point\n","  \"\"\"\n","  average_predictions = np.mean(pool_forward_pass, axis=0)\n","  all_entropies = entropy(average_predictions, axis=1) \n","  return all_entropies"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R7OzRacyU1qc","colab_type":"code","colab":{}},"source":["#Active learning Parameters/Settings\n","dropout_prob = 0.3\n","num_experiments = 3\n","num_acquisitions = 1000\n","pool_sample_size = 2500\n","num_masks = 50\n","\n","batch_size = 1\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wd2nVe4fU36r","colab_type":"code","outputId":"e010fe3a-d40c-463b-b3d6-4a55083196db","executionInfo":{"status":"ok","timestamp":1588348987061,"user_tz":240,"elapsed":86553,"user":{"displayName":"Udai Nagpal","photoUrl":"","userId":"01029084257713971836"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["#Loading Data\n","data_path = \"/content/gdrive/My Drive/FINAL_PAPER_ACTIVE_LEARNING_EXP/MNIST/\"\n","starting_ind_path = \"/content/gdrive/My Drive/FINAL_PAPER_ACTIVE_LEARNING_EXP/MNIST/Binary_7_9_AL_Scripts/\"\n","results_path = \"/content/gdrive/My Drive/FINAL_PAPER_ACTIVE_LEARNING_EXP/MNIST/Binary_7_9_AL_Results/\"\n","train_data = np.loadtxt(data_path + \"mnist_train.csv\", \n","\t\t\tdelimiter=\",\")\n","test_data = np.loadtxt(data_path + \"mnist_test.csv\", \n","\t\t\tdelimiter=\",\") \n","y_train_All = train_data[:,0]\n","y_test = test_data[:,0]\n","X_train_All = train_data[:,1:].reshape((60000,28,28))\n","X_test = test_data[:,1:].reshape((10000,28,28)) \n","train_ind = np.concatenate((np.argwhere(y_train_All==7), np.argwhere(y_train_All==9))).flatten()\n","test_ind = np.concatenate((np.argwhere(y_test==7), np.argwhere(y_test==9))).flatten()\n","y_test = y_test[test_ind]\n","y_test[y_test==9] = 0\n","y_test[y_test==7]= 1\n","y_test_original = y_test\n","y_test = keras.utils.to_categorical(y_test, num_classes=2)\n","X_test = np.expand_dims(X_test[test_ind], axis=1)\n","\n","#Iterating across experiments, each of which begins with a different training set (that is balanced across classes)\n","#Note: code is currently set up to *resume* an active learning experiment\n","#To start an active learning experiment from scratch, several lines below that are commented out should be uncommented, and vice versa\n","\n","for e in range(0,1):\n","  acc_file = \"MaxEnt_BS\"+str(batch_size)+\"_Acc_Ind\" + str(e+1) + \".npy\"\n","  ind_file = \"MaxEnt_BS\"+str(batch_size)+\"_Ind_Ind\" + str(e+1) + \".npy\"\n","  #exp_acc = []\n","  exp_acc = list(np.load(results_path+acc_file))\n","  #train_data_indices = list(np.load(starting_ind_path + 'trainindices' + str(e+1) + '.npy'))\n","  train_data_indices = list(np.load(results_path+ind_file))\n","  num_acquisitions = num_acquisitions - batch_size * (len(exp_acc) - 1)\n","  pool_indices = [i for i in train_ind if i not in train_data_indices]\n","  #Looping over active learning iterations\n","  for acq in range(num_acquisitions//batch_size + 1):\n","    #Selecting candidate points for acquisition\n","    pool_ind_sample = np.random.choice(pool_indices, pool_sample_size, replace=False)\n","    #Obtaining current model performance and MC dropout pool predictions\n","    model_results = run_model(train_data_indices, pool_ind_sample)\n","    if acq != 0:\n","      exp_acc.append(model_results[0])\n","    pool_forward_pass_results = model_results[1]  \n","    #Maximum entropy acquisition of new points\n","    acq_fn_values = get_acquisition_fn(pool_forward_pass_results) \n","    all_acq_ind_ind = np.flip(np.argsort(acq_fn_values))[0:batch_size]\n","    for acq_ind_ind in all_acq_ind_ind:\n","      train_data_indices.append(pool_ind_sample[acq_ind_ind])\n","      pool_indices.remove(pool_ind_sample[acq_ind_ind])\n","    #Saving results\n","    np.save(results_path+acc_file, np.array(exp_acc))\n","    np.save(results_path+ind_file, np.array(train_data_indices))\n","    print('Exp ' + str(e+1) + ', Number elapsed iterations: ' + str(len(exp_acc)) + \", last acc: \" + str(exp_acc[-1]))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, kernel_regularizer=<keras.reg...)`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, kernel_regularizer=<keras.reg...)`\n"],"name":"stderr"},{"output_type":"stream","text":["Exp 1, Number elapsed iterations: 1001, last acc: 0.9945999018163967\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PEQbt9cyrpT6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6emo3ngmsu09","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}